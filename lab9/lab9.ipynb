{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "152e8vBhE69LejI4jJRjp9ZF1vMQ77UBX",
      "authorship_tag": "ABX9TyOFZlBLPSdaap4RF7XXscK/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolulka/NeuralNetworks/blob/main/lab9/lab9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cIR1of1lKOk"
      },
      "source": [
        "Лаб. 9.1\n",
        "Задание 1.  (из  темы  9.1):\n",
        "\n",
        "Дообучите нейронную сеть VGG16 для распознавания изображений только двух классов. Используйте дообученную сеть для классификации своих изображений.\n",
        "\n",
        "Примеры для темы 9\n",
        "\n",
        "Задание 2.  (из  темы  9.2):\n",
        "\n",
        "Дообучите нейронную сеть ResNet34 распознаванию Вашего лица на фотографии. Используйте дообученную сеть для распознавания Вашего лица на других фотографиях (другой возраст; другой ракурс; часть лица закрыта, например, очками).\n",
        "\n",
        "Пример кода: https://github.com/sozykin/dlpython_course/blob/master/computer_vision/foto_comparison/foto_verification.ipynb\n",
        "\n",
        "В качестве входных данных подайте свои изображения (задания 1-2).\n",
        "\n",
        "В качестве результатов - результаты распознавания (задание 1) и анализ результатов (задание 2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtcXPFNzlPzM"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# Размер изображений\n",
        "img_width, img_height = 150, 150\n",
        "# Путь к каталогу с изображениями для обучения\n",
        "train_data_dir = '/content/drive/MyDrive/Colab Notebooks/data/train'\n",
        "# Путь к каталогу с изображениями для валидации\n",
        "validation_data_dir = '/content/drive/MyDrive/Colab Notebooks/data/validation'\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 32\n",
        "# Количество изображений для валидации\n",
        "nb_validation_samples = 8\n",
        "# Количество эпох\n",
        "epochs = 5\n",
        "# Размер выборки\n",
        "batch_size = 16\n",
        "\n",
        "# Загружаем сеть VGG16 без части, которая отвечает за классификацию\n",
        "base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Добавляем слои классификации\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# Выходной слой с двумя нейронами для классов \"кот\" и \"собака\"\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Составляем сеть из двух частей\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# \"Замораживаем\" сверточные уровни сети VGG16\n",
        "# Обучаем только вновь добавленные слои\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Создаем генератор данных для обучения\n",
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Создаем генератор данных для валидации\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Обучаем модель с помощью генератора\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples)\n",
        "\n",
        "print(\"Сохраняем сеть\")\n",
        "# Сохраняем сеть для последующего использования\n",
        "# Генерируем описание модели в формате json\n",
        "model_json = model.to_json()\n",
        "json_file = open(\"vgg16_cat_dogs.json\", \"w\")\n",
        "# Записываем архитектуру сети в файл\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "# Записываем данные о весах в файл\n",
        "model.save_weights(\"vgg16_cat_dogs.h5\")\n",
        "print(\"Сохранение сети завершено\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdYaKdptlQzH"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Список классов\n",
        "classes = ['кот', 'собака']\n",
        "\n",
        "#Загружаем обученную модель\n",
        "json_file = open(\"vgg16_cat_dogs.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"vgg16_cat_dogs.h5\")\n",
        "\n",
        "#Компилируем модель\n",
        "loaded_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Загружаем изображение для распознавания\n",
        "img = image.load_img('dog.jpg', target_size=(224, 224))\n",
        "# img = image.load_img('cat_dog.jpg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "#Запускаем распознавание\n",
        "prediction = loaded_model.predict(x)\n",
        "print(prediction)\n",
        "print(classes[np.argmax(prediction)])\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R8GVuBekoyp"
      },
      "source": [
        "import dlib\n",
        "from skimage import io\n",
        "from scipy.spatial import distance\n",
        "\n",
        "sp = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "facerec = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "img = io.imread('pic1.jpg')\n",
        "\n",
        "dets = detector(img, 1)\n",
        "for k, d in enumerate(dets):\n",
        "    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
        "        k, d.left(), d.top(), d.right(), d.bottom()))\n",
        "    shape = sp(img, d)\n",
        "\n",
        "\n",
        "face_descriptor1 = facerec.compute_face_descriptor(img, shape)\n",
        "# print(face_descriptor1)\n",
        "\n",
        "img = io.imread('pic2.jpg')\n",
        "dets_webcam = detector(img, 1)\n",
        "for k, d in enumerate(dets_webcam):\n",
        "    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
        "        k, d.left(), d.top(), d.right(), d.bottom()))\n",
        "    shape = sp(img, d)\n",
        "\n",
        "face_descriptor2 = facerec.compute_face_descriptor(img, shape)\n",
        "\n",
        "a = distance.euclidean(face_descriptor1, face_descriptor2)\n",
        "print(a)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7vHQ+93jcURSHnn6COFVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolulka/NeuralNetworks/blob/main/lab5/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osR8Z68LPH2G"
      },
      "source": [
        "Задание 1.  (из  темы  5.1):\n",
        "\n",
        "Выполните базовую версию программы обучения нейронной сети распознаванию рукописных цифр."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1NDeW50PGy9"
      },
      "source": [
        "import numpy\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "# Добавляем уровни сети\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=200, epochs=100, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQr_NJyGXlJ0"
      },
      "source": [
        "Задание 2.  (из  темы  5.1):\n",
        "\n",
        "Попытайтесь улучшить качество обучения сети путем изменения гиперпараметров: количество эпох обучения,\n",
        "размер мини-выборки, количество нейронов во входном слое, количество скрытых слоев. Для этого проведите\n",
        "серию экспериментов, в каждом из которых меняйте один из гиперпараметров, и анализируйте, как изменилось\n",
        "качество работы сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gjIj7ERDXuPW"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "numpy.random.seed(42)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# model.add(Dense(500, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "# model.add(Dense(700, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "# model.add(Dense(800, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "# model.add(Dense(900, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "model.add(Dense(1200, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "'''\n",
        "neurons number:\n",
        "500 - 92.53%\n",
        "700 - 92.94%\n",
        "800 - 92.93%\n",
        "900 - 93.06%\n",
        "1200 - 93.58% - best\n",
        "'''\n",
        "\n",
        "'''\n",
        "neurons number:\n",
        "500 - 94.49%\n",
        "600 - 94.43%\n",
        "700 - 94.64%\n",
        "900 - 94.94%\n",
        "1200 - 95.19% - best\n",
        "'''\n",
        "model.add(Dense(1200, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "# model.fit(X_train, Y_train, batch_size=50, epochs=5, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=50, epochs=50, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=50, epochs=75, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=50, epochs=100, validation_split=0.2, verbose=2)\n",
        "model.fit(X_train, Y_train, batch_size=50, epochs=125, validation_split=0.2, verbose=2)\n",
        "'''\n",
        "epochs number:\n",
        "5 - 92.93%\n",
        "50 - 97.52%\n",
        "75 - 97.84%\n",
        "100 - 97.98%\n",
        "125 - 98.03% - best\n",
        "'''\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=50, epochs=125, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=100, epochs=125, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=200, epochs=125, validation_split=0.2, verbose=2)\n",
        "# model.fit(X_train, Y_train, batch_size=400, epochs=125, validation_split=0.2, verbose=2)\n",
        "'''\n",
        "batch size:\n",
        "50 - 92.93% - best\n",
        "100 - 91.59%\n",
        "200 - 90.34%\n",
        "400 - 88.47%\n",
        "'''\n",
        "\n",
        "\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "'''98.00%'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-o7pp6X0qe"
      },
      "source": [
        "Задание 3  (из темы 5.1):\n",
        "\n",
        "Создайте сеть с лучшими значениями гиперпараметров.\n",
        "\n",
        "Задание 1.  (из  темы  6.1):\n",
        "\n",
        "Сохраните обученую нейронную сеть распознавания рукописных цифр."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UvP8RYimX5A5"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Устанавливаем seed для повторяемости результатов\n",
        "numpy.random.seed(42)\n",
        "\n",
        "# Загружаем данные\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразование размерности изображений\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "# Нормализация данных\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Преобразуем метки в категории\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Создаем последовательную модель\n",
        "model = Sequential()\n",
        "\n",
        "# Добавляем уровни сети\n",
        "model.add(Dense(1200, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
        "model.add(Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Обучаем сеть\n",
        "model.fit(X_train, Y_train, batch_size=50, epochs=125, validation_split=0.2, verbose=2)\n",
        "\n",
        "# Оцениваем качество обучения сети на тестовых данных\n",
        "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Точность работы на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# Генерируем описание модели в формате json\n",
        "model_json = model.to_json()\n",
        "# Записываем модель в файл\n",
        "json_file = open(\"mnist_model.json\", \"w\")\n",
        "json_file.write(model_json)\n",
        "json_file.close()\n",
        "\n",
        "model.save_weights(\"mnist_model.h5\")\n",
        "\n",
        "print (\"Сохранили Model\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}